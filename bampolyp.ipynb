{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eb85623"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "import glob\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from torch.utils.checkpoint import checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Axial Mamba Module\n",
        "\n",
        "class AxialMambaBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Axial Mamba block: applies Mamba mixing along height and width axes separately.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, args):\n",
        "        super(AxialMambaBlock, self).__init__()\n",
        "        self.args = args\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # Projections for height-axis Mamba\n",
        "        self.height_down = nn.Conv2d(in_channels, args.model_input_dims, kernel_size=1, bias=False)\n",
        "        self.height_mamba = MambaBlock(args)\n",
        "        self.height_up = nn.Conv2d(args.model_input_dims, out_channels, kernel_size=1, bias=False)\n",
        "        self.height_norm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Projections for width-axis Mamba\n",
        "        self.width_down = nn.Conv2d(in_channels, args.model_input_dims, kernel_size=1, bias=False)\n",
        "        self.width_mamba = MambaBlock(args)\n",
        "        self.width_up = nn.Conv2d(args.model_input_dims, out_channels, kernel_size=1, bias=False)\n",
        "        self.width_norm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.skip_proj = nn.Identity() if in_channels == out_channels else nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        h_proj = self.height_down(x)\n",
        "        h_seq = rearrange(h_proj, 'b d h w -> (b w) h d')\n",
        "        h_seq = self.height_mamba(h_seq)\n",
        "        h_mixed = rearrange(h_seq, '(b w) h d -> b d h w', b=b, w=w)\n",
        "        h_out = self.height_up(h_mixed)\n",
        "        h_out = self.height_norm(h_out)\n",
        "\n",
        "        w_proj = self.width_down(x)\n",
        "        w_seq = rearrange(w_proj, 'b d h w -> (b h) w d')\n",
        "        w_seq = self.width_mamba(w_seq)\n",
        "        w_mixed = rearrange(w_seq, '(b h) w d -> b d h w', b=b, h=h)\n",
        "        w_out = self.width_up(w_mixed)\n",
        "        w_out = self.width_norm(w_out)\n",
        "\n",
        "        skip = self.skip_proj(x)\n",
        "        out = h_out + w_out + skip\n",
        "        return out"
      ],
      "metadata": {
        "id": "-oW8XeAfx9nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Double Convolution Block\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "QdYV6MJVyJCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def selective_scan(u, delta, A, B, C, D):\n",
        "    A = torch.clamp(A, min=-5.0, max=5.0)\n",
        "    dA = torch.einsum('bld,dn->bldn', delta, A)\n",
        "    dB_u = torch.einsum('bld,bld,bln->bldn', delta, u, B)\n",
        "    dA_cumsum = torch.cat([dA[:, 1:], torch.zeros_like(dA[:, :1])], dim=1)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "    dA_cumsum = torch.cumsum(dA_cumsum, dim=1)\n",
        "    dA_cumsum = torch.clamp(dA_cumsum, max=15.0)\n",
        "    dA_cumsum = torch.exp(dA_cumsum)\n",
        "    dA_cumsum = torch.flip(dA_cumsum, dims=[1])\n",
        "    x = dB_u * dA_cumsum\n",
        "    x = torch.cumsum(x, dim=1) / (dA_cumsum + 1e-6)\n",
        "    y = torch.einsum('bldn,bln->bld', x, C)\n",
        "    return y + u * D\n",
        "\n",
        "\n",
        "class MambaBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(MambaBlock, self).__init__()\n",
        "        self.args = args\n",
        "        self.in_proj = nn.Linear(args.model_input_dims, args.model_internal_dim * 2, bias=False)\n",
        "        self.conv1d = nn.Conv1d(\n",
        "            args.model_internal_dim,\n",
        "            args.model_internal_dim,\n",
        "            kernel_size=args.conv_kernel_size,\n",
        "            padding=args.conv_kernel_size - 1,\n",
        "            groups=args.model_internal_dim\n",
        "        )\n",
        "        self.x_proj = nn.Linear(args.model_internal_dim, args.delta_t_rank + args.model_states * 2, bias=False)\n",
        "        self.delta_proj = nn.Linear(args.delta_t_rank, args.model_internal_dim)\n",
        "\n",
        "        A_vals = torch.arange(1, args.model_states + 1).float() / args.model_states * 3\n",
        "        self.A_log = nn.Parameter(torch.log(repeat(A_vals, 'n -> d n', d=args.model_internal_dim)))\n",
        "        self.D = nn.Parameter(torch.ones(args.model_internal_dim))\n",
        "        self.out_proj = nn.Linear(args.model_internal_dim, args.model_input_dims, bias=args.dense_use_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            return torch.utils.checkpoint.checkpoint(self._forward, x)\n",
        "        return self._forward(x)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        b, l, d = x.shape\n",
        "        x_and_res = self.in_proj(x)\n",
        "        x1, res = x_and_res.chunk(2, dim=-1)\n",
        "\n",
        "        x1 = rearrange(x1, 'b l d -> b d l')\n",
        "        x1 = self.conv1d(x1)[..., :l]\n",
        "        x1 = rearrange(x1, 'b d l -> b l d')\n",
        "        x1 = F.silu(x1)\n",
        "\n",
        "        A = -torch.exp(torch.clamp(self.A_log, min=-5, max=5))\n",
        "        D = self.D\n",
        "        x_dbl = self.x_proj(x1)\n",
        "        delta, B, C = torch.split(\n",
        "            x_dbl,\n",
        "            [self.args.delta_t_rank, self.args.model_states, self.args.model_states],\n",
        "            dim=-1\n",
        "        )\n",
        "        delta = F.softplus(self.delta_proj(delta))\n",
        "\n",
        "        y = selective_scan(x1, delta, A, B, C, D)\n",
        "        y = y * F.silu(res)\n",
        "        return self.out_proj(y)"
      ],
      "metadata": {
        "id": "BwjvELc-yNbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.norm1 = nn.LayerNorm(args.model_input_dims)\n",
        "        self.mixer = MambaBlock(args)\n",
        "        self.dropout = nn.Dropout(args.dropout_rate)\n",
        "        self.norm2 = nn.LayerNorm(args.model_input_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.mixer(x)\n",
        "        x = self.dropout(x)\n",
        "        x = residual + x\n",
        "        return self.norm2(x)\n",
        "\n",
        "class ModelArgs:\n",
        "    def __init__(self):\n",
        "        self.model_input_dims = 96\n",
        "        self.model_states = 96\n",
        "        self.projection_expand_factor = 2\n",
        "        self.conv_kernel_size = 4\n",
        "        self.dense_use_bias = False\n",
        "        self.dropout_rate = 0.2\n",
        "        self.num_layers = 6\n",
        "        self.num_classes = 2\n",
        "        self.model_internal_dim = self.projection_expand_factor * self.model_input_dims\n",
        "        self.delta_t_rank = math.ceil(self.model_input_dims / 16)\n",
        "\n",
        "class IoULoss(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(IoULoss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        inputs_soft = F.softmax(inputs, dim=1)\n",
        "        num_classes = inputs.shape[1]\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        dims = (2, 3)\n",
        "        intersection = (inputs_soft * targets_one_hot).sum(dim=dims)\n",
        "        union = (inputs_soft + targets_one_hot - inputs_soft * targets_one_hot).sum(dim=dims) + self.eps\n",
        "\n",
        "        iou = (intersection + self.eps) / union\n",
        "        iou_loss = 1.0 - iou\n",
        "        return iou_loss.mean()"
      ],
      "metadata": {
        "id": "gso-ghHLyTiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        inputs_soft = F.softmax(inputs, dim=1)\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=inputs.shape[1])\n",
        "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        intersection = (inputs_soft * targets_one_hot).sum(dim=(2, 3))\n",
        "        cardinality = inputs_soft.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
        "        dice_score = (2. * intersection + self.eps) / (cardinality + self.eps)\n",
        "        return 1.0 - dice_score.mean()\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, weight=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "        self.ce = nn.CrossEntropyLoss(weight=weight, reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        logpt = -self.ce(inputs, targets)\n",
        "        pt = torch.exp(logpt)\n",
        "        focal_term = ((1 - pt) ** self.gamma) * logpt\n",
        "        loss = -focal_term\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class TverskyLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5, beta=0.5, eps=1e-6):\n",
        "        super(TverskyLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        inputs_soft = F.softmax(inputs, dim=1)\n",
        "        num_classes = inputs.shape[1]\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=num_classes)\n",
        "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        dims = (2, 3)\n",
        "        TP = (inputs_soft * targets_one_hot).sum(dim=dims)\n",
        "        FP = (inputs_soft * (1 - targets_one_hot)).sum(dim=dims)\n",
        "        FN = ((1 - inputs_soft) * targets_one_hot).sum(dim=dims)\n",
        "\n",
        "        tversky_index = (TP + self.eps) / (TP + self.alpha * FP + self.beta * FN + self.eps)\n",
        "        return (1.0 - tversky_index).mean()\n",
        "\n",
        "\n",
        "class IoULoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(IoULoss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        inputs_soft = F.softmax(inputs, dim=1)\n",
        "        num_classes = inputs.shape[1]\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=num_classes)\n",
        "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        dims = (2, 3)\n",
        "        intersection = (inputs_soft * targets_one_hot).sum(dim=dims)\n",
        "        union = inputs_soft.sum(dim=dims) + targets_one_hot.sum(dim=dims) - intersection\n",
        "        iou = (intersection + self.eps) / (union + self.eps)\n",
        "        return (1.0 - iou).mean()\n",
        "\n",
        "\n",
        "class BoundaryLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, eps: float = 1e-6):\n",
        "        super(BoundaryLoss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def _get_boundary(self, mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        m = mask.unsqueeze(1)\n",
        "        inv = 1.0 - m\n",
        "        eroded_inv = F.max_pool2d(inv, kernel_size=3, stride=1, padding=1)\n",
        "        eroded = 1.0 - eroded_inv\n",
        "        b = m - eroded\n",
        "        return b.squeeze(1)\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        B, C, H, W = inputs.shape\n",
        "        probs = F.softmax(inputs, dim=1)\n",
        "        gt = F.one_hot(targets, num_classes=C).permute(0,3,1,2).float()\n",
        "\n",
        "        loss = 0.0\n",
        "        for c in range(C):\n",
        "            p_c = probs[:, c, :, :]\n",
        "            g_c = gt[:, c, :, :]\n",
        "            b_pred = self._get_boundary(p_c)\n",
        "            b_gt   = self._get_boundary(g_c)\n",
        "            inter = (b_pred * b_gt).sum(dim=(1,2))\n",
        "            union = b_pred.sum(dim=(1,2)) + b_gt.sum(dim=(1,2))\n",
        "            dice_b = (2.0 * inter + self.eps) / (union + self.eps)\n",
        "            loss += (1.0 - dice_b).mean()\n",
        "        return loss / C\n",
        "\n",
        "\n",
        "class ComboLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Weighted sum of BCE, Dice, Focal, Tversky, IoU, and Boundary losses.\n",
        "    Loss weights are dataset-specific and detailed in the README and paper.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 bce_weight=0.15,\n",
        "                 dice_weight=0.25,\n",
        "                 focal_weight=0.2,\n",
        "                 tversky_weight=0.15,\n",
        "                 iou_weight=0.15,\n",
        "                 boundary_weight=0.1,\n",
        "                 focal_gamma=2.0,\n",
        "                 tversky_alpha=0.5,\n",
        "                 tversky_beta=0.5):\n",
        "        super(ComboLoss, self).__init__()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.dice_weight = dice_weight\n",
        "        self.focal_weight = focal_weight\n",
        "        self.tversky_weight = tversky_weight\n",
        "        self.iou_weight = iou_weight\n",
        "        self.boundary_weight = boundary_weight\n",
        "\n",
        "        self.ce_loss       = nn.CrossEntropyLoss()\n",
        "        self.dice_loss     = DiceLoss()\n",
        "        self.focal_loss    = FocalLoss(gamma=focal_gamma, reduction='mean')\n",
        "        self.tversky_loss  = TverskyLoss(alpha=tversky_alpha, beta=tversky_beta)\n",
        "        self.iou_loss      = IoULoss()\n",
        "        self.boundary_loss = BoundaryLoss()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        loss_bce      = self.ce_loss(inputs, targets)\n",
        "        loss_dice     = self.dice_loss(inputs, targets)\n",
        "        loss_focal    = self.focal_loss(inputs, targets)\n",
        "        loss_tversky  = self.tversky_loss(inputs, targets)\n",
        "        loss_iou      = self.iou_loss(inputs, targets)\n",
        "        loss_boundary = self.boundary_loss(inputs, targets)\n",
        "\n",
        "        total = (\n",
        "            self.bce_weight      * loss_bce\n",
        "            + self.dice_weight   * loss_dice\n",
        "            + self.focal_weight  * loss_focal\n",
        "            + self.tversky_weight* loss_tversky\n",
        "            + self.iou_weight    * loss_iou\n",
        "            + self.boundary_weight * loss_boundary\n",
        "        )\n",
        "        return total\n"
      ],
      "metadata": {
        "id": "OJINBA_Dyaap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepSupervisionLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, main_weight=0.6, deep2_weight=0.2, deep3_weight=0.2):\n",
        "        super(DeepSupervisionLoss, self).__init__()\n",
        "        self.main_weight = main_weight\n",
        "        self.deep2_weight = deep2_weight\n",
        "        self.deep3_weight = deep3_weight\n",
        "        self.criterion = ComboLoss(\n",
        "            bce_weight=0.2,\n",
        "            dice_weight=0.3,\n",
        "            focal_weight=0.2,\n",
        "            tversky_weight=0.2,\n",
        "            iou_weight=0.3,\n",
        "            focal_gamma=2.0,\n",
        "            tversky_alpha=0.5,\n",
        "            tversky_beta=0.5\n",
        "        )\n",
        "\n",
        "    def forward(self, outputs, target):\n",
        "\n",
        "        main_out, deep2, deep3, *_ = outputs\n",
        "        loss_main = self.criterion(main_out, target)\n",
        "        loss_deep2 = self.criterion(deep2, target)\n",
        "        loss_deep3 = self.criterion(deep3, target)\n",
        "        total_loss = (\n",
        "            self.main_weight * loss_main +\n",
        "            self.deep2_weight * loss_deep2 +\n",
        "            self.deep3_weight * loss_deep3\n",
        "        )\n",
        "        return total_loss"
      ],
      "metadata": {
        "id": "86IFc6eSyiOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "\n",
        "    pred_mask = (pred_mask > 0).cpu().numpy().astype(bool)\n",
        "    gt_mask = (gt_mask > 0).cpu().numpy().astype(bool)\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
        "    if union == 0:\n",
        "        return 1.0\n",
        "    return intersection / union\n",
        "\n",
        "def calculate_dice(pred_mask, gt_mask):\n",
        "\n",
        "    pred_mask = (pred_mask > 0).cpu().numpy().astype(bool)\n",
        "    gt_mask = (gt_mask > 0).cpu().numpy().astype(bool)\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    sum_areas = pred_mask.sum() + gt_mask.sum()\n",
        "    if sum_areas == 0:\n",
        "        return 1.0\n",
        "    return 2.0 * intersection / sum_areas\n",
        "\n",
        "\n",
        "def plot_training_progress(history, epoch):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history['train_iou'], label='Train IoU')\n",
        "    plt.plot(history['val_iou'], label='Val IoU')\n",
        "    plt.title('IoU')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history['train_dice'], label='Train Dice')\n",
        "    plt.plot(history['val_dice'], label='Val Dice')\n",
        "    plt.title('Dice')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/kaggle/working/training_progress_epoch_{epoch}.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "dHHH0HMiymwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function\n",
        "\n",
        "def train_one_epoch_enhanced(model, dataloader, optimizer, criterion, device, scheduler=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    running_dice = 0.0\n",
        "    sample_count = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, desc='Training')\n",
        "    for i, (images, masks) in enumerate(pbar):\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        if i == 0:\n",
        "            print(f\"Training batch - Images: {images.shape}, Masks: {masks.shape}\")\n",
        "            print(f\"Masks unique values: {torch.unique(masks)}\")\n",
        "\n",
        "        outputs = model(images, return_deep=True)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        main_output = outputs[0]\n",
        "        batch_size = images.size(0)\n",
        "        preds = torch.argmax(main_output, dim=1)\n",
        "\n",
        "        running_loss += loss.item() * batch_size\n",
        "\n",
        "        batch_iou = 0.0\n",
        "        batch_dice = 0.0\n",
        "        for j in range(batch_size):\n",
        "            iou = calculate_iou(preds[j], masks[j])\n",
        "            dice = calculate_dice(preds[j], masks[j])\n",
        "            batch_iou += iou\n",
        "            batch_dice += dice\n",
        "\n",
        "        running_iou += batch_iou\n",
        "        running_dice += batch_dice\n",
        "        sample_count += batch_size\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'loss': loss.item(),\n",
        "            'iou': batch_iou / batch_size,\n",
        "            'dice': batch_dice / batch_size\n",
        "        })\n",
        "\n",
        "        del outputs, loss, preds\n",
        "        if i % 10 == 0 and torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    epoch_loss = running_loss / sample_count\n",
        "    epoch_iou = running_iou / sample_count\n",
        "    epoch_dice = running_dice / sample_count\n",
        "    return epoch_loss, epoch_iou, epoch_dice\n",
        "\n",
        "# Validation Function\n",
        "\n",
        "def validate_enhanced(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_iou = 0.0\n",
        "    running_dice = 0.0\n",
        "    sample_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(dataloader, desc='Validation'):\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images, return_deep=True)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            main_output = outputs[0]\n",
        "            batch_size = images.size(0)\n",
        "            preds = torch.argmax(main_output, dim=1)\n",
        "\n",
        "            running_loss += loss.item() * batch_size\n",
        "            for j in range(batch_size):\n",
        "                iou = calculate_iou(preds[j], masks[j])\n",
        "                dice = calculate_dice(preds[j], masks[j])\n",
        "                running_iou += iou\n",
        "                running_dice += dice\n",
        "\n",
        "            sample_count += batch_size\n",
        "\n",
        "    val_loss = running_loss / sample_count\n",
        "    val_iou = running_iou / sample_count\n",
        "    val_dice = running_dice / sample_count\n",
        "    return val_loss, val_iou, val_dice\n",
        "\n",
        "# Visualization Function\n",
        "\n",
        "def visualize_results(model, dataloader, device, num_samples=3):\n",
        "    import matplotlib.pyplot as plt\n",
        "    model.eval()\n",
        "\n",
        "    images, masks = next(iter(dataloader))\n",
        "    images = images[:num_samples].to(device)\n",
        "    masks = masks[:num_samples].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)\n",
        "    images = images * std + mean\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
        "    for i in range(num_samples):\n",
        "        axes[i, 0].imshow(images[i].permute(1, 2, 0).cpu().numpy())\n",
        "        axes[i, 0].set_title(\"Original Image\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "\n",
        "        axes[i, 1].imshow(masks[i].cpu().numpy(), cmap=\"gray\")\n",
        "        axes[i, 1].set_title(\"Ground Truth\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "\n",
        "        axes[i, 2].imshow(predictions[i].cpu().numpy(), cmap=\"gray\")\n",
        "        axes[i, 2].set_title(\"Prediction\")\n",
        "        axes[i, 2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/kaggle/working/mamba_segmentation_with_axial_mamba_aspp_ppm_iou_results.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LW_3hUT3ysWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import efficientnet_b0\n",
        "\n",
        "class MambaUNetWithAxialMambaEfficientNetB0(nn.Module):\n",
        "    def __init__(self, args, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "\n",
        "        #EfficientNetB0 pretrained\n",
        "        backbone = efficientnet_b0(pretrained=True)\n",
        "\n",
        "        if in_channels != 3:\n",
        "            self.stem = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "                backbone.features[0][1],\n",
        "                backbone.features[0][2],\n",
        "            )\n",
        "        else:\n",
        "            self.stem = backbone.features[0]\n",
        "\n",
        "        # Encoder stages\n",
        "        self.stage1 = backbone.features[1]\n",
        "        self.stage2 = backbone.features[2]\n",
        "        self.stage3 = backbone.features[3]\n",
        "        self.stage4 = backbone.features[4]\n",
        "        self.stage5 = nn.Sequential(\n",
        "            backbone.features[5],\n",
        "            backbone.features[6],\n",
        "            backbone.features[7],\n",
        "        )\n",
        "\n",
        "        # Axial Mamba bottleneck\n",
        "        self.axial_mamba = AxialMambaBlock(320, 320, args)\n",
        "\n",
        "\n",
        "        self.bridge_down = nn.Conv2d(320, args.model_input_dims, kernel_size=1)\n",
        "        self.mamba_blocks = nn.Sequential(*[ResidualBlock(args) for _ in range(args.num_layers)])\n",
        "        self.bridge_up = nn.Conv2d(args.model_input_dims, 320, kernel_size=1)\n",
        "\n",
        "        self.bottleneck_refine = nn.Sequential(\n",
        "            nn.Conv2d(320, 320, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv4 = nn.ConvTranspose2d(320, 160, kernel_size=2, stride=2)\n",
        "        self.decoder4 = DoubleConv(160 + 80, 160)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(160, 80, kernel_size=2, stride=2)\n",
        "        self.decoder3 = DoubleConv(80 + 40, 80)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(80, 40, kernel_size=2, stride=2)\n",
        "        self.decoder2 = DoubleConv(40 + 24, 40)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(40, 24, kernel_size=2, stride=2)\n",
        "        self.decoder1 = DoubleConv(24 + in_channels, 24)\n",
        "\n",
        "        # Final conv and deep supervision\n",
        "        self.final_conv = nn.Conv2d(24, args.num_classes, kernel_size=1)\n",
        "        self.deep_sup4 = nn.Conv2d(160, args.num_classes, kernel_size=1)\n",
        "        self.deep_sup3 = nn.Conv2d(80, args.num_classes, kernel_size=1)\n",
        "        self.deep_sup2 = nn.Conv2d(40, args.num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, return_deep=False):\n",
        "        x0 = self.stem(x)\n",
        "        e1 = self.stage1(x0)\n",
        "        e2 = self.stage2(e1)\n",
        "        e3 = self.stage3(e2)\n",
        "        e4 = self.stage4(e3)\n",
        "        e5 = self.stage5(e4)\n",
        "\n",
        "        axial_out = self.axial_mamba(e5)\n",
        "        bottleneck_feat = axial_out\n",
        "\n",
        "        mamba_in = self.bridge_down(bottleneck_feat)\n",
        "        b, c, h, w = mamba_in.shape\n",
        "        m_in = mamba_in.permute(0, 2, 3, 1).reshape(b, h * w, c)\n",
        "        m_out = self.mamba_blocks(m_in)\n",
        "        m_out = m_out.reshape(b, h, w, c).permute(0, 3, 1, 2)\n",
        "        mamba_out = self.bridge_up(m_out)\n",
        "\n",
        "        bottleneck_out = self.bottleneck_refine(mamba_out + bottleneck_feat)\n",
        "\n",
        "        d4 = self.upconv4(bottleneck_out)\n",
        "        if d4.shape[2:] != e4.shape[2:]:\n",
        "            d4 = F.interpolate(d4, size=e4.shape[2:], mode='bilinear', align_corners=False)\n",
        "        d4 = self.decoder4(torch.cat([d4, e4], dim=1))\n",
        "        ds4 = self.deep_sup4(d4)\n",
        "\n",
        "        d3 = self.upconv3(d4)\n",
        "        if d3.shape[2:] != e3.shape[2:]:\n",
        "            d3 = F.interpolate(d3, size=e3.shape[2:], mode='bilinear', align_corners=False)\n",
        "        d3 = self.decoder3(torch.cat([d3, e3], dim=1))\n",
        "        ds3 = self.deep_sup3(d3)\n",
        "\n",
        "        d2 = self.upconv2(d3)\n",
        "        if d2.shape[2:] != e2.shape[2:]:\n",
        "            d2 = F.interpolate(d2, size=e2.shape[2:], mode='bilinear', align_corners=False)\n",
        "        d2 = self.decoder2(torch.cat([d2, e2], dim=1))\n",
        "        ds2 = self.deep_sup2(d2)\n",
        "\n",
        "        d1 = self.upconv1(d2)\n",
        "        if d1.shape[2:] != x.shape[2:]:\n",
        "            d1 = F.interpolate(d1, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "        d1 = self.decoder1(torch.cat([d1, x], dim=1))\n",
        "\n",
        "        out = self.final_conv(d1)\n",
        "        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        if return_deep:\n",
        "            ds2_up = F.interpolate(ds2, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "            ds3_up = F.interpolate(ds3, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "            ds4_up = F.interpolate(ds4, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "            return out, ds2_up, ds3_up, ds4_up\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VZGnVfXz3q0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def download_and_setup_dataset(force_download=False):\n",
        "    base_path = '/kaggle/working/datasets'\n",
        "    kvasir_path = os.path.join(base_path, 'kvasir-seg')\n",
        "\n",
        "    kaggle_input_path = '/kaggle/input'\n",
        "    for dirname, _, _ in os.walk(kaggle_input_path):\n",
        "        if 'kvasir-seg' in dirname.lower() and os.path.exists(os.path.join(dirname, 'images')):\n",
        "            print(f\"Found Kvasir-SEG dataset at {dirname}\")\n",
        "            return dirname\n",
        "\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    #If images/masks exist already and no forced download is required, return path,\n",
        "    #This is similar to the check used for PolypGen, ClinicDB, and ColonDB Datasets\n",
        "\n",
        "    if (os.path.exists(os.path.join(kvasir_path, 'images')) and\n",
        "        os.path.exists(os.path.join(kvasir_path, 'masks')) and\n",
        "        len(os.listdir(os.path.join(kvasir_path, 'images'))) > 0 and\n",
        "        not force_download):\n",
        "        print(\"Kvasir-SEG dataset already exists.\")\n",
        "        return kvasir_path\n",
        "\n",
        "    # Direct download for Kvasir-SEG from public URL (others use kagglehub)\n",
        "    # For datasets like ClinicDB, ColonDB or PolypGen, replace this section with kagglehub.dataset_download(X)\n",
        "    # X = \"balraj98/cvcclinicdb\"(ClinicDB) ; \"longvil/cvc-colondb\"(ColonDB) ; \"kokoroou/polypgen2021\"(PolypGen)\n",
        "\n",
        "    dataset_url = \"https://datasets.simula.no/downloads/kvasir-seg.zip\"\n",
        "    zip_path = os.path.join(base_path, 'kvasir-seg.zip')\n",
        "\n",
        "    print(\"Downloading Kvasir-SEG dataset...\")\n",
        "    try:\n",
        "        response = requests.get(dataset_url, stream=True)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        block_size = 1024\n",
        "        progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for data in response.iter_content(block_size):\n",
        "                progress_bar.update(len(data))\n",
        "                f.write(data)\n",
        "        progress_bar.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Download completed, file saved to {zip_path}\")\n",
        "\n",
        "    # Extract the zip (in PolypGen and others, this step is not needed as kagglehub provides unzipped folders)\n",
        "    print(\"Extracting dataset...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(base_path)\n",
        "        print(\"Extraction completed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "    extracted_files = glob.glob(os.path.join(base_path, \"**\"), recursive=True)\n",
        "    print(\"Extracted file structure:\")\n",
        "    for file in extracted_files[:10]:\n",
        "        print(f\"  {file}\")\n",
        "    if len(extracted_files) > 10:\n",
        "        print(f\"  ... and {len(extracted_files)-10} more files\")\n",
        "\n",
        "    image_dirs = glob.glob(os.path.join(base_path, \"**/images\"), recursive=True)\n",
        "    mask_dirs = glob.glob(os.path.join(base_path, \"**/masks\"), recursive=True)\n",
        "\n",
        "    print(f\"Found image directories: {image_dirs}\")\n",
        "    print(f\"Found mask directories: {mask_dirs}\")\n",
        "\n",
        "    # Create unified 'images' and 'masks' folders under /kvasir-seg for consistency\n",
        "    # In other dataset codes, this is also done to standardize directory structure\n",
        "\n",
        "    os.makedirs(os.path.join(kvasir_path, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(kvasir_path, 'masks'), exist_ok=True)\n",
        "\n",
        "    # For all datasets, src_image_dir and src_mask_dir are taken from glob results\n",
        "    if image_dirs and mask_dirs:\n",
        "        src_image_dir = image_dirs[0]\n",
        "        src_mask_dir = mask_dirs[0]\n",
        "\n",
        "        if src_image_dir != os.path.join(kvasir_path, 'images'):\n",
        "            print(f\"Moving images from {src_image_dir} to {os.path.join(kvasir_path, 'images')}\")\n",
        "            for img_file in os.listdir(src_image_dir):\n",
        "                shutil.copy(\n",
        "                    os.path.join(src_image_dir, img_file),\n",
        "                    os.path.join(kvasir_path, 'images', img_file)\n",
        "                )\n",
        "\n",
        "        if src_mask_dir != os.path.join(kvasir_path, 'masks'):\n",
        "            print(f\"Moving masks from {src_mask_dir} to {os.path.join(kvasir_path, 'masks')}\")\n",
        "            for mask_file in os.listdir(src_mask_dir):\n",
        "                shutil.copy(\n",
        "                    os.path.join(src_mask_dir, mask_file),\n",
        "                    os.path.join(kvasir_path, 'masks', mask_file)\n",
        "                )\n",
        "\n",
        "    try:\n",
        "        os.remove(zip_path)\n",
        "        print(\"Removed zip file.\")\n",
        "    except:\n",
        "        print(\"Could not remove zip file.\")\n",
        "\n",
        "    # Final check to confirm setup — used in all dataset scripts\n",
        "    if (os.path.exists(os.path.join(kvasir_path, 'images')) and\n",
        "        os.path.exists(os.path.join(kvasir_path, 'masks')) and\n",
        "        len(os.listdir(os.path.join(kvasir_path, 'images'))) > 0):\n",
        "        print(\"Dataset setup completed successfully.\")\n",
        "        print(f\"Found {len(os.listdir(os.path.join(kvasir_path, 'images')))} images and \"\n",
        "              f\"{len(os.listdir(os.path.join(kvasir_path, 'masks')))} masks.\")\n",
        "        return kvasir_path\n",
        "    else:\n",
        "        print(\"Dataset setup failed.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ccjIAVDtzBTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class KvasirSEGDataset(Dataset):   #Change according to the dataset used\n",
        "    def __init__(self, root_dir, split='train', transform=None, target_transform=None, augment=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.augment = augment and split == 'train'\n",
        "        self.img_dir = os.path.join(root_dir, 'images')\n",
        "        self.mask_dir = os.path.join(root_dir, 'masks')\n",
        "\n",
        "        if not os.path.exists(self.img_dir):\n",
        "            raise ValueError(f\"Images directory not found: {self.img_dir}\")\n",
        "        if not os.path.exists(self.mask_dir):\n",
        "            raise ValueError(f\"Masks directory not found: {self.mask_dir}\")\n",
        "\n",
        "        self.images = sorted([f for f in os.listdir(self.img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        if not self.images:\n",
        "            raise ValueError(f\"No images found in {self.img_dir}\")\n",
        "\n",
        "        print(f\"Sample image names: {self.images[:5]}\")\n",
        "\n",
        "        np.random.seed(42)\n",
        "        indices = np.random.permutation(len(self.images))\n",
        "\n",
        "        if split == 'train':\n",
        "            self.images = [self.images[i] for i in indices[:int(0.8 * len(self.images))]]\n",
        "        elif split == 'val':\n",
        "            self.images = [self.images[i] for i in indices[int(0.8 * len(self.images)):int(0.9 * len(self.images))]]\n",
        "        else:\n",
        "            self.images = [self.images[i] for i in indices[int(0.9 * len(self.images)):]]\n",
        "\n",
        "        print(f\"Created {split} dataset with {len(self.images)} images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        base_name = os.path.splitext(img_name)[0]\n",
        "        mask_candidates = [\n",
        "            os.path.join(self.mask_dir, base_name + ext)\n",
        "            for ext in ['.jpg', '.png', '.jpeg', '.tif']\n",
        "        ]\n",
        "        mask_path = next((path for path in mask_candidates if os.path.exists(path)), None)\n",
        "\n",
        "        if not mask_path:\n",
        "            mask_files = os.listdir(self.mask_dir)\n",
        "            matches = [f for f in mask_files if f.startswith(base_name)]\n",
        "            if matches:\n",
        "                mask_path = os.path.join(self.mask_dir, matches[0])\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"No mask found for image {img_name}\")\n",
        "\n",
        "        if idx == 0:\n",
        "            print(f\"Image path: {img_path}\")\n",
        "            print(f\"Mask path: {mask_path}\")\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.augment:\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.hflip(image)\n",
        "                mask = TF.hflip(mask)\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.vflip(image)\n",
        "                mask = TF.vflip(mask)\n",
        "            if random.random() > 0.5:\n",
        "                angle = random.choice([90, 180, 270])\n",
        "                fill = 0\n",
        "                image = TF.rotate(image, angle, fill=fill)\n",
        "                mask = TF.rotate(mask, angle, fill=fill)\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.adjust_brightness(image, random.uniform(0.8, 1.2))\n",
        "                image = TF.adjust_contrast(image, random.uniform(0.8, 1.2))\n",
        "                image = TF.adjust_saturation(image, random.uniform(0.8, 1.2))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "        else:\n",
        "            mask_array = np.array(mask)\n",
        "            mask_binary = (mask_array > 0).astype(np.int64)\n",
        "            mask = torch.from_numpy(mask_binary).long()\n",
        "\n",
        "        if idx == 0:\n",
        "            print(f\"Image shape: {image.shape}, dtype: {image.dtype}, range: [{image.min()}, {image.max()}]\")\n",
        "            print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}, range: [{mask.min()}, {mask.max()}]\")\n",
        "\n",
        "        if mask.dim() == 3 and mask.size(0) == 1:\n",
        "            mask = mask.squeeze(0)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "Ng9FowNYzIPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Running on:\", device)\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "\n",
        "    kvasir_path = download_and_setup_dataset(force_download=False)\n",
        "    if not kvasir_path:\n",
        "        print(\"Dataset setup failed. Exiting...\")\n",
        "        return\n",
        "\n",
        "    transform = T.Compose([\n",
        "        T.Resize((256, 256)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    target_transform = T.Compose([\n",
        "        T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),\n",
        "        T.ToTensor(),\n",
        "        lambda x: (x > 0.5).long()\n",
        "    ])\n",
        "\n",
        "    try:\n",
        "        train_dataset = KvasirSEGDataset(\n",
        "            kvasir_path,\n",
        "            split='train',\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            augment=True\n",
        "        )\n",
        "        val_dataset = KvasirSEGDataset(\n",
        "            kvasir_path,\n",
        "            split='val',\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            augment=False\n",
        "        )\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=4,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=True if torch.cuda.is_available() else False\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=4,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            pin_memory=True if torch.cuda.is_available() else False\n",
        "        )\n",
        "        print(\"Data loaders created successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating datasets: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    args = ModelArgs()\n",
        "    model = MambaUNetWithAxialMambaEfficientNetB0(args).to(device)\n",
        "\n",
        "    criterion = DeepSupervisionLoss(main_weight=0.6, deep2_weight=0.2, deep3_weight=0.2)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer,\n",
        "        T_0=10,\n",
        "        T_mult=2,\n",
        "        eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    num_epochs = 300\n",
        "    best_iou = 0.0\n",
        "    patience_counter = 0\n",
        "    max_patience = 300\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_iou': [], 'train_dice': [],\n",
        "        'val_loss': [], 'val_iou': [], 'val_dice': []\n",
        "    }\n",
        "\n",
        "    print(f\"Starting training for {num_epochs} epochs...\")\n",
        "    try:\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            train_loss, train_iou, train_dice = train_one_epoch_enhanced(\n",
        "                model, train_loader, optimizer, criterion, device, scheduler\n",
        "            )\n",
        "            val_loss, val_iou, val_dice = validate_enhanced(\n",
        "                model, val_loader, criterion, device\n",
        "            )\n",
        "\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_iou'].append(train_iou)\n",
        "            history['train_dice'].append(train_dice)\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_iou'].append(val_iou)\n",
        "            history['val_dice'].append(val_dice)\n",
        "\n",
        "            print(f\"Train → Loss: {train_loss:.4f}, IoU: {train_iou:.4f}, Dice: {train_dice:.4f}\")\n",
        "            print(f\"Val   → Loss: {val_loss:.4f}, IoU: {val_iou:.4f}, Dice: {val_dice:.4f}\")\n",
        "\n",
        "            if val_iou > best_iou:\n",
        "                best_iou = val_iou\n",
        "                torch.save(model.state_dict(), \"/kaggle/working/best_mamba_unet_axial_mamba_aspp_ppm_iou.pth\")\n",
        "                print(f\"Model saved with IoU: {best_iou:.4f}\")\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'best_iou': best_iou,\n",
        "                    'history': history,\n",
        "                }, f\"/kaggle/working/checkpoint_axial_mamba_aspp_ppm_iou_epoch_{epoch+1}.pth\")\n",
        "                plot_training_progress(history, epoch + 1)\n",
        "\n",
        "            if patience_counter >= max_patience:\n",
        "                print(f\"Early stopping after {max_patience} epochs without improvement\")\n",
        "                break\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        torch.save({\n",
        "            'epoch': epoch if 'epoch' in locals() else 0,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if 'scheduler' in locals() else None,\n",
        "            'best_iou': best_iou if 'best_iou' in locals() else 0,\n",
        "            'history': history,\n",
        "        }, \"/kaggle/working/error_checkpoint_axial_mamba_aspp_ppm_iou.pth\")\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(\"/kaggle/working/best_mamba_unet_axial_mamba_aspp_ppm_iou.pth\"))\n",
        "        print(\"Loaded best model for evaluation\")\n",
        "    except:\n",
        "        print(\"Could not load best model, using current model\")\n",
        "\n",
        "    visualize_results(model, val_loader, device)\n",
        "    print(\"Training and evaluation completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ODR1sKAHzOEr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "args = ModelArgs()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MambaUNetWithAxialMambaEfficientNetB0(args).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"/kaggle/working/best_mamba_unet_axial_mamba_aspp_ppm_iou.pth\"))\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "target_transform = T.Compose([\n",
        "    T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),\n",
        "    T.ToTensor(),\n",
        "    lambda x: (x > 0.5).long()\n",
        "])\n",
        "kvasir_path = download_and_setup_dataset(force_download=False)\n",
        "val_dataset = KvasirSEGDataset(kvasir_path, split='val', transform=transform, target_transform=target_transform, augment=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B4wBhvkocs6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import torch\n",
        "\n",
        "def evaluate_precision_recall_f1(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images, return_deep=True)\n",
        "            main_output = outputs[0]\n",
        "\n",
        "            preds = torch.argmax(main_output, dim=1)\n",
        "            masks = masks.squeeze(1)\n",
        "\n",
        "            all_preds.append(preds.cpu().numpy().reshape(-1))\n",
        "            all_labels.append(masks.cpu().numpy().reshape(-1))\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    return precision, recall, f1\n"
      ],
      "metadata": {
        "id": "61hnjNOcfFIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, f1 = evaluate_precision_recall_f1(model, val_loader, device)\n",
        "print(f\"Final Validation Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "sfHPrE47fI8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "Mg8IKt2jou0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from torchinfo import summary\n",
        "import torch\n",
        "\n",
        "args = ModelArgs()\n",
        "model = MambaUNetWithAxialMambaEfficientNetB0(args)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "summary(model, input_size=(1, 3, 256, 256), device=str(device), depth=4)\n"
      ],
      "metadata": {
        "id": "gl_rwcSeotyy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sXh-7W_midz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import profile\n",
        "\n",
        "model.eval()\n",
        "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
        "flops = 2 * macs\n",
        "\n",
        "print(f\"Params: {params / 1e6:.2f} M\")\n",
        "print(f\"MACs: {macs / 1e9:.2f} G\")\n",
        "print(f\"FLOPs: {flops / 1e9:.2f} G\")\n"
      ],
      "metadata": {
        "id": "84ND8d6libi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "def measure_inference_time(model, input_size=(1, 3, 256, 256), device='cuda', repeat=100):\n",
        "    model.eval().to(device)\n",
        "    input_tensor = torch.randn(*input_size).to(device)\n",
        "\n",
        "    for _ in range(10):\n",
        "        _ = model(input_tensor)\n",
        "\n",
        "    torch.cuda.synchronize() if device == 'cuda' else None\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(repeat):\n",
        "            _ = model(input_tensor)\n",
        "\n",
        "    torch.cuda.synchronize() if device == 'cuda' else None\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_inference_time = (end_time - start_time) / repeat * 1000\n",
        "    print(f\"Average Inference Time: {avg_inference_time:.3f} ms per image\")\n",
        "\n",
        "model = MambaUNetWithAxialMambaEfficientNetB0(ModelArgs())\n",
        "measure_inference_time(model, input_size=(1, 3, 256, 256), device='cuda', repeat=100)\n"
      ],
      "metadata": {
        "id": "6QBC1mRVjjAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}